{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "beneficial-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "brazilian-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_companies_from_search_category(category, location=False, numberofreviews=0, status=\"all\",\n",
    "                                         timeperiode=0, page=1, verbose=0, scrap_best_score=True,\n",
    "                                        max_companies=-1, max_reviews=-1):\n",
    "    \n",
    "    \"\"\"\n",
    "    func :  scrap all results from a category search on trustpilor and return dict\n",
    "            on their site, first results are companies_with_best_score and then they are all results\n",
    "            in facts I don't see any difference between those results, so I add an arg scrap_best_score, if it sets True we scrap only firsts results,\n",
    "            else we scrap only seconds results (if we scrap both of them we get only doublons)\n",
    "            on the other way, the site shows 20+ results if we are not on the last page, that's why I count them with companies_count\n",
    "            if companies_count < 20 then we are on the last page\n",
    "            by the way, the site himself provides doublons, so if the link is already in our dic, we skip it\n",
    "    \n",
    "    params:\n",
    "        category : str -> category_link to search\n",
    "        location : str -> code postal or ville\n",
    "        numberofreviews : int -> must be in [0, 25, 50, 100, 250, 500]\n",
    "        status : str -> must be in [\"all\", \"unclaimed\", \"claimed\", \"\"]\n",
    "        timeperiode : int -> must be in [0, 6, 12, 18]\n",
    "        page : int -> load this page and higher\n",
    "        verboses : bool -> print steps\n",
    "        scrap_best_score : bool -> scrap best_score_companies or ALL (no difference between them, set this param to True it's faster)\n",
    "        max_companies : int -> exit func when nb_companies >= max_companies\n",
    "        max_reviews : int -> exit func when nb_reviews >= max_reviews\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://fr.trustpilot.com/categories/\" + category + \"?\"\n",
    "    if location:\n",
    "        url += \"location=\" + location + \"&\"\n",
    "    url += \"numberofreviews=\" + str(numberofreviews) + \"&\"\n",
    "    if status != \"\":\n",
    "        url += \"status=\" + status + \"&\"\n",
    "    url += \"timeperiode=\" + str(timeperiode) + \"&\"\n",
    "    url += \"page=\"\n",
    "    \n",
    "    companies = {\"name\": [], \"link\": [], \"stars\": [], \"review_count\": [], \"location\": [], \"category\": []}\n",
    "    total_reviews = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        \n",
    "        req = requests.get(url + str(page))\n",
    "        if verbose > 0:\n",
    "            print(url + str(page))\n",
    "        try:\n",
    "            soup = BeautifulSoup(req.text, \"lxml\")\n",
    "        except:\n",
    "            soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        \n",
    "        company_count_on_page = 0\n",
    "        \n",
    "        # possibly 2 blocks of companies (most rated and all)\n",
    "        div_containers = soup.find_all(\"div\", class_=\"styles_businessUnitCardsContainer__1ggaO\")\n",
    "\n",
    "        for div_container in div_containers:\n",
    "            # for each block\n",
    "            div = div_container.find(\"div\", class_=\"styles_categoryBusinessListWrapper__2H2X5\")\n",
    "            \n",
    "            companies_with_best_score = True\n",
    "            if div == None:\n",
    "                # if we find div with 2H2X5 class it's companies_with_best_score so we need to enter in this div\n",
    "                # else it's all we don't have to enter anywhere\n",
    "                div = div_container\n",
    "                companies_with_best_score = False\n",
    "                \n",
    "            a_balises = div.find_all(\"a\")\n",
    "            for a_balise in a_balises:\n",
    "                \n",
    "                # if not companies_with_best_score, we don't want to scrap, only to count them to know if we are on last page\n",
    "                if scrap_best_score:\n",
    "                    if not companies_with_best_score:\n",
    "                        continue\n",
    "                else:\n",
    "                    if companies_with_best_score:\n",
    "                        company_count_on_page += 1\n",
    "                        continue\n",
    "                \n",
    "                # for each entreprise, find link, title, stars\n",
    "                link = a_balise[\"href\"].split(\"/\")[-1]\n",
    "                title = a_balise.find(\"div\", class_=\"styles_businessTitle__1IANo\").text\n",
    "                \n",
    "                # try to get more info if they have\n",
    "                try:\n",
    "                    infos_div = a_balise.find(\"div\", class_=\"styles_textRating__19_fv\").text\n",
    "                    infos = infos_div.split(\"\\xa0·\\xa0\")\n",
    "                    infos[0] = int(infos[0].split()[0])\n",
    "                    infos[1] = float(infos[1].split()[-1])\n",
    "                except:\n",
    "                    if verbose == 2:\n",
    "                        print(\"No stars and nb_reviews for\", title, link)\n",
    "                    infos = [np.nan, np.nan]\n",
    "                # try to get location  if they have\n",
    "                try:\n",
    "                    div_locations = a_balise.find(\"div\", class_=\"styles_location__3JATO\")\n",
    "                    spans_location = div_locations.find_all(\"span\", class_=None)\n",
    "                    location = \"\"\n",
    "                    if spans_location != None:\n",
    "                        i = 0\n",
    "                        while i < len(spans_location):\n",
    "                            location += spans_location[i].text\n",
    "                            if i == 0:\n",
    "                                location += \" . \"\n",
    "                            i += 1\n",
    "                except:\n",
    "                    if verbose == 2:\n",
    "                        print(\"No location for\", title, link)\n",
    "                    location = np.nan\n",
    "\n",
    "                # if this is a doublon we skip it\n",
    "                if link in companies[\"link\"]:\n",
    "                    company_count_on_page += 1\n",
    "                    continue\n",
    "                    \n",
    "                # add infos in dic\n",
    "                companies[\"name\"].append(title)\n",
    "                companies[\"link\"].append(link)\n",
    "                companies[\"stars\"].append(infos[1])\n",
    "                companies[\"review_count\"].append(infos[0])\n",
    "                companies[\"location\"].append(location)\n",
    "                companies[\"category\"].append(category)\n",
    "                \n",
    "                total_reviews += infos[0]\n",
    "\n",
    "                company_count_on_page += 1\n",
    "                \n",
    "                \n",
    "        if max_reviews > 0 and total_reviews >= max_reviews:\n",
    "            return companies\n",
    "        if max_companies > 0 and len(companies[\"name\"]) >= max_companies:\n",
    "            return companies\n",
    "        if verbose > 0:   \n",
    "            print(f\"nb company on page {page} : {company_count_on_page}\")\n",
    "        if company_count_on_page >= 20:\n",
    "            page += 1\n",
    "            time.sleep(random.uniform(0.5, 1.5))\n",
    "        else:\n",
    "            done = True\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "reasonable-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_reviews_from_company(company, page=1, max_reviews=-1, verbose=0):\n",
    "    url = \"https://fr.trustpilot.com/review/\" + company + \"?page=\"\n",
    "    \n",
    "    reviews = {\"consumer_name\": [], \"consumer_nb_review_writed\": [], \"stars\": [],\n",
    "               \"title_review\": [], \"content_review\": [], \"date_experience\": [], \"company\": []}\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        req = requests.get(url + str(page))\n",
    "        if verbose > 0:\n",
    "            print(url + str(page))\n",
    "        try:\n",
    "            soup = BeautifulSoup(req.text, \"lxml\")\n",
    "        except:\n",
    "            soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        \n",
    "        nb_review_on_page = 0\n",
    "        review_list = soup.find(\"div\", class_=\"review-list\")\n",
    "        review_cards = review_list.find_all(\"div\", class_=\"review-card\")\n",
    "        \n",
    "        for review_card in review_cards:\n",
    "            \n",
    "            #consumer_name\n",
    "            consumer_name = \" \".join(review_card.find(\"div\", class_=\"consumer-information__name\").text.split())\n",
    "            \n",
    "            #consumer_nb_review_writed\n",
    "            consumer_nb_review_writed = review_card.find(\"div\", class_=\"consumer-information__review-count\").find(\"span\").text.split()[0]\n",
    "            \n",
    "            #stars\n",
    "            stars = review_card.find(\"div\", class_=\"star-rating star-rating--medium\").find(\"img\")[\"alt\"].split()[0]\n",
    "            \n",
    "            #title_review\n",
    "            title_review = \" \".join(review_card.find(\"h2\", class_=\"review-content__title\").find(\"a\").text.split())\n",
    "            \n",
    "            #content_review\n",
    "            try:\n",
    "                content_review = \" \".join(review_card.find(\"p\", class_=\"review-content__text\").text.split())\n",
    "            except:\n",
    "                content_review = np.nan\n",
    "            \n",
    "            #date_experience\n",
    "            try:\n",
    "                date_experience = \" \".join(review_card.find(\"p\", class_=\"review-content__dateOfExperience\").text.split(\":\")[-1].split())\n",
    "            except:\n",
    "                date_experience = np.nan\n",
    "                \n",
    "            #add to dic\n",
    "            reviews[\"consumer_name\"].append(consumer_name)\n",
    "            reviews[\"consumer_nb_review_writed\"].append(int(consumer_nb_review_writed))\n",
    "            reviews[\"stars\"].append(int(stars))\n",
    "            reviews[\"title_review\"].append(title_review)\n",
    "            reviews[\"content_review\"].append(content_review)\n",
    "            reviews[\"date_experience\"].append(date_experience)\n",
    "            reviews[\"company\"].append(company)\n",
    "            \n",
    "            #count nb of reviews\n",
    "            nb_review_on_page += 1\n",
    "        \n",
    "        if max_reviews > 0 and len(reviews[\"consumer_name\"]) >= max_reviews:\n",
    "                return reviews\n",
    "        if verbose > 0:\n",
    "            print(f\"nb_review_on_page {page} : {nb_review_on_page}\")\n",
    "            \n",
    "        if nb_review_on_page < 20:\n",
    "            done = True\n",
    "        else:\n",
    "            page += 1\n",
    "            time.sleep(random.uniform(0.5, 1.5))\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "treated-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_companies_and_reviews_from_search_category(category, location=False, numberofreviews=0, status=\"all\",\n",
    "                                         timeperiode=0, max_companies=-1, max_reviews_by_companies=-1, verbose=0):\n",
    "    \n",
    "    #scrap companies\n",
    "    companies = scrap_companies_from_search_category(category, location=location, numberofreviews=numberofreviews, status=status,\n",
    "                                                    timeperiode=timeperiode, max_companies=max_companies)\n",
    "    if verbose > 0:\n",
    "        print(\"scrap companies DONE\")\n",
    "    \n",
    "    #scrap reviews\n",
    "    reviews = {\"consumer_name\": [], \"consumer_nb_review_writed\": [], \"stars\": [],\n",
    "               \"title_review\": [], \"content_review\": [], \"date_experience\": [], \"company\": []}\n",
    "    for company_link in companies[\"link\"]:\n",
    "        #get reviews of each company\n",
    "        new_reviews = scrap_reviews_from_company(company_link, max_reviews=max_reviews_by_companies)\n",
    "        if verbose > 0:\n",
    "            print(f\"scrap reviews of {company_link} DONE\")\n",
    "            \n",
    "        #join those reviews whith reviews of all companies\n",
    "        for key, value in reviews.items():\n",
    "            reviews[key] = reviews[key] + new_reviews[key]\n",
    "        \n",
    "    return companies, reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sweet-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = pd.read_csv(\"csv/categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "front-terrain",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_beverages_tobacco\n",
      "scrap companies DONE\n",
      "scrap reviews of www.lepetitvapoteur.com DONE\n",
      "scrap reviews of www.comptoirdesvignes.fr DONE\n",
      "scrap reviews of monwhisky.fr DONE\n",
      "scrap reviews of cafesbelleville.com DONE\n",
      "scrap reviews of spiruline-des-iles-dor.com DONE\n",
      "scrap reviews of demainlesvins.com DONE\n",
      "scrap reviews of au-droit-de-bouchon.com DONE\n",
      "scrap reviews of stephconti.fr DONE\n",
      "scrap reviews of alcoool.fr DONE\n",
      "scrap reviews of entrepotitalien.fr DONE\n",
      "scrap reviews of www.rhumattitude.com DONE\n",
      "scrap reviews of vert-tiges.com DONE\n",
      "scrap reviews of lafourche.fr DONE\n",
      "scrap reviews of www.oliquide.com DONE\n",
      "scrap reviews of nutri-naturel.com DONE\n",
      "scrap reviews of lepetitballon.com DONE\n",
      "scrap reviews of cafe-en-grain.com DONE\n",
      "scrap reviews of vintageandco.com DONE\n",
      "scrap reviews of boutique.lushan.fr DONE\n",
      "scrap reviews of www.peche-maison.fr DONE\n",
      "scrap reviews of www.vincentdanslesvapes.fr DONE\n",
      "scrap reviews of cbdtoulouse.fr DONE\n",
      "scrap reviews of oeforgood.com DONE\n",
      "scrap reviews of lomi.coffee DONE\n",
      "scrap reviews of vignartea.fr DONE\n",
      "scrap reviews of malindo.fr DONE\n",
      "scrap reviews of e-winery.fr DONE\n",
      "scrap reviews of champagne-terroir.fr DONE\n",
      "scrap reviews of dockdesepices.com DONE\n",
      "scrap reviews of hayuco.coffee DONE\n",
      "scrap reviews of www.nordictemptations.com DONE\n",
      "scrap reviews of lacouleurduvin.fr DONE\n",
      "scrap reviews of lafrenchi.fr DONE\n",
      "scrap reviews of lebongustave.com DONE\n",
      "scrap reviews of lestresorsdumarocbyzayti.com DONE\n",
      "scrap reviews of monplancbd.fr DONE\n",
      "scrap reviews of e-vapopote.fr DONE\n",
      "scrap reviews of lepetitzeste.com DONE\n",
      "scrap reviews of nutrimuscle.com DONE\n",
      "scrap reviews of ecigplanete.com DONE\n"
     ]
    }
   ],
   "source": [
    "print(df_categories[\"link\"][0])\n",
    "companies, reviews = scrap_companies_and_reviews_from_search_category(df_categories[\"link\"][0], max_companies=60,\n",
    "                                                                      max_reviews_by_companies=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "numerical-shopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>location</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le Petit Vapoteur</td>\n",
       "      <td>www.lepetitvapoteur.com</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comptoir des Vignes</td>\n",
       "      <td>www.comptoirdesvignes.fr</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MonWhisky.fr</td>\n",
       "      <td>monwhisky.fr</td>\n",
       "      <td>4.9</td>\n",
       "      <td>849</td>\n",
       "      <td>4 rue Alfred Dreyfus . 87350PANAZOL</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Belleville Brulerie - Paris</td>\n",
       "      <td>cafesbelleville.com</td>\n",
       "      <td>4.9</td>\n",
       "      <td>819</td>\n",
       "      <td>14 Bis Rue Lally-Tollendal . 75019Paris</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiruline des îles d'or</td>\n",
       "      <td>spiruline-des-iles-dor.com</td>\n",
       "      <td>4.9</td>\n",
       "      <td>400</td>\n",
       "      <td>1143 Chemin de la Garde . 83400Hyères</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name                        link  stars  \\\n",
       "0            Le Petit Vapoteur     www.lepetitvapoteur.com    4.9   \n",
       "1          Comptoir des Vignes    www.comptoirdesvignes.fr    4.9   \n",
       "2                 MonWhisky.fr                monwhisky.fr    4.9   \n",
       "3  Belleville Brulerie - Paris         cafesbelleville.com    4.9   \n",
       "4      Spiruline des îles d'or  spiruline-des-iles-dor.com    4.9   \n",
       "\n",
       "   review_count                                 location  \\\n",
       "0          3149                                      NaN   \n",
       "1          2208                                      NaN   \n",
       "2           849      4 rue Alfred Dreyfus . 87350PANAZOL   \n",
       "3           819  14 Bis Rue Lally-Tollendal . 75019Paris   \n",
       "4           400    1143 Chemin de la Garde . 83400Hyères   \n",
       "\n",
       "                 category  \n",
       "0  food_beverages_tobacco  \n",
       "1  food_beverages_tobacco  \n",
       "2  food_beverages_tobacco  \n",
       "3  food_beverages_tobacco  \n",
       "4  food_beverages_tobacco  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_companies = pd.DataFrame(companies)\n",
    "print(df_companies.shape)\n",
    "display(df_companies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "particular-contest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19408, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_name</th>\n",
       "      <th>consumer_nb_review_writed</th>\n",
       "      <th>stars</th>\n",
       "      <th>title_review</th>\n",
       "      <th>content_review</th>\n",
       "      <th>date_experience</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Helrat</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Toujours parfait</td>\n",
       "      <td>Toujours parfait. Depuis 4 ans, je commande to...</td>\n",
       "      <td>14 mars 2021</td>\n",
       "      <td>www.lepetitvapoteur.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laura Perrault</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Site aussi bon que d'habitude ou l'on…</td>\n",
       "      <td>Site aussi bon que d'habitude ou l'on trouve p...</td>\n",
       "      <td>8 mars 2021</td>\n",
       "      <td>www.lepetitvapoteur.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HENRY KARINE</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Présentation agréable, conseils rapides et ada...</td>\n",
       "      <td>11 mars 2021</td>\n",
       "      <td>www.lepetitvapoteur.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>le chineur</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Bonne presentation et explication des…</td>\n",
       "      <td>Bonne presentation et explication des produits...</td>\n",
       "      <td>10 mars 2021</td>\n",
       "      <td>www.lepetitvapoteur.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antoine Thomas</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Site génial pour commander son matériel…</td>\n",
       "      <td>Site génial pour commander son matériel et ses...</td>\n",
       "      <td>10 mars 2021</td>\n",
       "      <td>www.lepetitvapoteur.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    consumer_name  consumer_nb_review_writed  stars  \\\n",
       "0          Helrat                          4      5   \n",
       "1  Laura Perrault                          1      5   \n",
       "2    HENRY KARINE                          2      5   \n",
       "3      le chineur                          2      5   \n",
       "4  Antoine Thomas                          1      5   \n",
       "\n",
       "                               title_review  \\\n",
       "0                          Toujours parfait   \n",
       "1    Site aussi bon que d'habitude ou l'on…   \n",
       "2                                    Super!   \n",
       "3    Bonne presentation et explication des…   \n",
       "4  Site génial pour commander son matériel…   \n",
       "\n",
       "                                      content_review date_experience  \\\n",
       "0  Toujours parfait. Depuis 4 ans, je commande to...    14 mars 2021   \n",
       "1  Site aussi bon que d'habitude ou l'on trouve p...     8 mars 2021   \n",
       "2  Présentation agréable, conseils rapides et ada...    11 mars 2021   \n",
       "3  Bonne presentation et explication des produits...    10 mars 2021   \n",
       "4  Site génial pour commander son matériel et ses...    10 mars 2021   \n",
       "\n",
       "                   company  \n",
       "0  www.lepetitvapoteur.com  \n",
       "1  www.lepetitvapoteur.com  \n",
       "2  www.lepetitvapoteur.com  \n",
       "3  www.lepetitvapoteur.com  \n",
       "4  www.lepetitvapoteur.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_name</th>\n",
       "      <th>consumer_nb_review_writed</th>\n",
       "      <th>stars</th>\n",
       "      <th>title_review</th>\n",
       "      <th>content_review</th>\n",
       "      <th>date_experience</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19403</th>\n",
       "      <td>M.B</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Cigarette électronique zlide</td>\n",
       "      <td>Excellent rapport qualité/prix. Livraison rapi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecigplanete.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19404</th>\n",
       "      <td>Patricia GAUJOUX</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Je reçois toujours mes colis dans des…</td>\n",
       "      <td>Je reçois toujours mes colis dans des délais r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecigplanete.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19405</th>\n",
       "      <td>Marlène</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Société compétitive et très réactive …</td>\n",
       "      <td>Société compétitive et très réactive dans les ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecigplanete.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19406</th>\n",
       "      <td>Florence Sevault</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Livraison rapide conforme à la commande…</td>\n",
       "      <td>Livraison rapide conforme à la commande emball...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecigplanete.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19407</th>\n",
       "      <td>Mademoiselle Virginie Pernet</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Erreur et problème, en continu</td>\n",
       "      <td>Deux commandes, deux problèmesPrix attractifs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecigplanete.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      consumer_name  consumer_nb_review_writed  stars  \\\n",
       "19403                           M.B                          1      5   \n",
       "19404              Patricia GAUJOUX                          1      5   \n",
       "19405                       Marlène                          1      5   \n",
       "19406              Florence Sevault                          1      5   \n",
       "19407  Mademoiselle Virginie Pernet                          2      1   \n",
       "\n",
       "                                   title_review  \\\n",
       "19403              Cigarette électronique zlide   \n",
       "19404    Je reçois toujours mes colis dans des…   \n",
       "19405    Société compétitive et très réactive …   \n",
       "19406  Livraison rapide conforme à la commande…   \n",
       "19407            Erreur et problème, en continu   \n",
       "\n",
       "                                          content_review date_experience  \\\n",
       "19403  Excellent rapport qualité/prix. Livraison rapi...             NaN   \n",
       "19404  Je reçois toujours mes colis dans des délais r...             NaN   \n",
       "19405  Société compétitive et très réactive dans les ...             NaN   \n",
       "19406  Livraison rapide conforme à la commande emball...             NaN   \n",
       "19407  Deux commandes, deux problèmesPrix attractifs ...             NaN   \n",
       "\n",
       "               company  \n",
       "19403  ecigplanete.com  \n",
       "19404  ecigplanete.com  \n",
       "19405  ecigplanete.com  \n",
       "19406  ecigplanete.com  \n",
       "19407  ecigplanete.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_reviews = pd.DataFrame(reviews)\n",
    "print(df_reviews.shape)\n",
    "display(df_reviews.head())\n",
    "display(df_reviews.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "thrown-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies.to_csv(\"scraped_companies.csv\", index=False)\n",
    "df_reviews.to_csv(\"scraped_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-yukon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
