{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "preliminary-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "agricultural-manner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45841 entries, 0 to 45840\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   consumer_name              45837 non-null  object \n",
      " 1   consumer_nb_review_writed  45841 non-null  int64  \n",
      " 2   stars                      45838 non-null  float64\n",
      " 3   title_review               45838 non-null  object \n",
      " 4   content_review             41364 non-null  object \n",
      " 5   date_experience            12615 non-null  object \n",
      " 6   company                    45841 non-null  object \n",
      " 7   category                   45841 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"csv/scraped_reviews.csv\", sep=\";\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sensitive-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41364 entries, 0 to 45840\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   consumer_name              41360 non-null  object \n",
      " 1   consumer_nb_review_writed  41364 non-null  int64  \n",
      " 2   stars                      41364 non-null  float64\n",
      " 3   title_review               41364 non-null  object \n",
      " 4   content_review             41364 non-null  object \n",
      " 5   date_experience            11138 non-null  object \n",
      " 6   company                    41364 non-null  object \n",
      " 7   category                   41364 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"content_review\"].notna()]\n",
    "df[\"stars\"] = df[\"stars\"].astype(int)\n",
    "df[\"review\"] = df[\"title_review\"] + \" \" + df[\"content_review\"]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "objective-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\theoj/.cache\\torch\\hub\\pytorch_fairseq_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "camembert = torch.hub.load('pytorch/fairseq', 'camembert.v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "southern-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaHubInterface(\n",
      "  (model): RobertaModel(\n",
      "    (encoder): RobertaEncoder(\n",
      "      (sentence_encoder): TransformerEncoder(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (embed_tokens): Embedding(32005, 768, padding_idx=1)\n",
      "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
      "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (1): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (2): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (3): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (4): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (5): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (6): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (7): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (8): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (9): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (10): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (11): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (lm_head): RobertaLMHead(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (classification_heads): ModuleDict()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(camembert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chemical-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"./data/\")\n",
    "LOG_PATH = Path(\"./logs/\")\n",
    "MODEL_PATH = Path(\"./model/\")\n",
    "LABEL_PATH = Path(\"./labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = df.sample(frac=0.2, replace=False, random_state=42)\n",
    "train_set = df.drop(index=val_set.index)\n",
    "print(\"nb commentaires dans le val_set:\", len(val_set))\n",
    "print(\"nb commentaires dans le train_set:\", len(train_set))\n",
    "val_set.to_csv(\"./data/val_set.csv\")\n",
    "train_set.to_csv(\"./data/train_set.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
